Search.setIndex({"docnames": ["bibliography", "index", "reference/abc", "reference/all", "reference/asset", "reference/classes", "reference/data", "reference/enums", "reference/functions", "reference/generated/abc/fairseq2.gang.Gang", "reference/generated/classes/fairseq2.optim.lr_scheduler.CosineAnnealingLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.MyleLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.NoamLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.PolynomialDecayLR", "reference/generated/data/fairseq2.assets.AssetCard", "reference/generated/data/fairseq2.assets.AssetMetadataProvider", "reference/generated/data/fairseq2.assets.AssetStore", "reference/generated/data/fairseq2.data.ByteStreamError", "reference/generated/data/fairseq2.data.CString", "reference/generated/data/fairseq2.data.CollateOptionsOverride", "reference/generated/data/fairseq2.data.Collater", "reference/generated/data/fairseq2.data.DataPipeline", "reference/generated/data/fairseq2.data.DataPipelineBuilder", "reference/generated/data/fairseq2.data.DataPipelineError", "reference/generated/data/fairseq2.data.FileMapper", "reference/generated/data/fairseq2.data.PathLike", "reference/generated/data/fairseq2.data.RecordError", "reference/generated/data/fairseq2.data.StringLike", "reference/generated/data/fairseq2.data.VocabularyInfo", "reference/generated/data/fairseq2.data.get_last_failed_example", "reference/generated/data/fairseq2.data.is_string_like", "reference/generated/data/fairseq2.data.list_files", "reference/generated/data/fairseq2.data.read_sequence", "reference/generated/data/fairseq2.data.read_zipped_records", "reference/generated/data/fairseq2.data.text.read_text", "reference/generated/data_text/fairseq2.data.text.LineEnding", "reference/generated/data_text/fairseq2.data.text.SentencePieceDecoder", "reference/generated/data_text/fairseq2.data.text.SentencePieceEncoder", "reference/generated/data_text/fairseq2.data.text.SentencePieceModel", "reference/generated/data_text/fairseq2.data.text.StrSplitter", "reference/generated/data_text/fairseq2.data.text.StrToIntConverter", "reference/generated/data_text/fairseq2.data.text.StrToTensorConverter", "reference/generated/data_text/fairseq2.data.text.TextTokenDecoder", "reference/generated/data_text/fairseq2.data.text.TextTokenEncoder", "reference/generated/data_text/fairseq2.data.text.TextTokenizer", "reference/generated/data_text/fairseq2.data.text.vocab_info_from_sentencepiece", "reference/generated/enums/fairseq2.nn.transformer.TransformerNormOrder", "reference/generated/functions/fairseq2.nn.utils.mask.to_float_mask"], "filenames": ["bibliography.rst", "index.rst", "reference/abc.rst", "reference/all.rst", "reference/asset.rst", "reference/classes.rst", "reference/data.rst", "reference/enums.rst", "reference/functions.rst", "reference/generated/abc/fairseq2.gang.Gang.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.CosineAnnealingLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.MyleLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.NoamLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.PolynomialDecayLR.rst", "reference/generated/data/fairseq2.assets.AssetCard.rst", "reference/generated/data/fairseq2.assets.AssetMetadataProvider.rst", "reference/generated/data/fairseq2.assets.AssetStore.rst", "reference/generated/data/fairseq2.data.ByteStreamError.rst", "reference/generated/data/fairseq2.data.CString.rst", "reference/generated/data/fairseq2.data.CollateOptionsOverride.rst", "reference/generated/data/fairseq2.data.Collater.rst", "reference/generated/data/fairseq2.data.DataPipeline.rst", "reference/generated/data/fairseq2.data.DataPipelineBuilder.rst", "reference/generated/data/fairseq2.data.DataPipelineError.rst", "reference/generated/data/fairseq2.data.FileMapper.rst", "reference/generated/data/fairseq2.data.PathLike.rst", "reference/generated/data/fairseq2.data.RecordError.rst", "reference/generated/data/fairseq2.data.StringLike.rst", "reference/generated/data/fairseq2.data.VocabularyInfo.rst", "reference/generated/data/fairseq2.data.get_last_failed_example.rst", "reference/generated/data/fairseq2.data.is_string_like.rst", "reference/generated/data/fairseq2.data.list_files.rst", "reference/generated/data/fairseq2.data.read_sequence.rst", "reference/generated/data/fairseq2.data.read_zipped_records.rst", "reference/generated/data/fairseq2.data.text.read_text.rst", "reference/generated/data_text/fairseq2.data.text.LineEnding.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceDecoder.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceEncoder.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceModel.rst", "reference/generated/data_text/fairseq2.data.text.StrSplitter.rst", "reference/generated/data_text/fairseq2.data.text.StrToIntConverter.rst", "reference/generated/data_text/fairseq2.data.text.StrToTensorConverter.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenDecoder.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenEncoder.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenizer.rst", "reference/generated/data_text/fairseq2.data.text.vocab_info_from_sentencepiece.rst", "reference/generated/enums/fairseq2.nn.transformer.TransformerNormOrder.rst", "reference/generated/functions/fairseq2.nn.utils.mask.to_float_mask.rst"], "titles": ["Bibliography", "fairseq2 documentation", "ABCs and Protocols", "All", "fairseq2.assets", "Classes", "fairseq2.data", "Enums", "Functions", "Gang", "CosineAnnealingLR", "MyleLR", "NoamLR", "PolynomialDecayLR", "AssetCard", "AssetMetadataProvider", "AssetStore", "fairseq2.data.ByteStreamError", "CString", "CollateOptionsOverride", "Collater", "DataPipeline", "DataPipelineBuilder", "fairseq2.data.DataPipelineError", "FileMapper", "PathLike", "fairseq2.data.RecordError", "StringLike", "VocabularyInfo", "get_last_failed_example", "is_string_like", "list_files", "read_sequence", "read_zipped_records", "read_text", "LineEnding", "SentencePieceDecoder", "SentencePieceEncoder", "SentencePieceModel", "StrSplitter", "StrToIntConverter", "StrToTensorConverter", "TextTokenDecoder", "TextTokenEncoder", "TextTokenizer", "vocab_info_from_sentencepiece", "TransformerNormOrder", "to_float_mask"], "terms": {"lh17": [0, 10], "ilya": 0, "loshchilov": [0, 10], "frank": 0, "hutter": [0, 10], "sgdr": 0, "stochast": 0, "gradient": 0, "descent": 0, "warm": 0, "restart": [0, 10], "2017": 0, "arxiv": 0, "1608": 0, "03983": 0, "swo21": [0, 46], "sam": 0, "shleifer": [0, 46], "jason": 0, "weston": 0, "myle": [0, 11], "ott": [0, 11], "normform": 0, "improv": 0, "transform": [0, 46], "pretrain": 0, "extra": 0, "normal": [0, 46], "2021": 0, "url": 0, "http": 0, "org": 0, "ab": 0, "2110": 0, "09456": 0, "doi": 0, "10": [0, 6, 22, 40], "48550": 0, "vsp": [0, 12, 46], "17": [0, 12, 46], "ashish": 0, "vaswani": [0, 12, 46], "noam": [0, 11, 12], "shazeer": [0, 12], "niki": 0, "parmar": 0, "jakob": 0, "uszkoreit": 0, "llion": 0, "jone": 0, "aidan": 0, "n": 0, "gomez": 0, "lukasz": 0, "kaiser": 0, "illia": 0, "polosukhin": 0, "attent": 0, "i": [0, 1, 4, 6, 10, 11, 12, 13, 20, 21, 22, 24, 26, 28, 30, 37, 43], "all": [0, 1, 4, 9, 10, 11, 13, 19, 20, 21, 22, 24, 31, 39], "you": [0, 6, 24], "need": [0, 20], "1706": 0, "03762": 0, "xyh": [0, 46], "20": [0, 46], "ruibin": 0, "xiong": [0, 46], "yunchang": 0, "yang": 0, "di": 0, "he": 0, "kai": 0, "zheng": 0, "shuxin": 0, "chen": 0, "xing": 0, "huishuai": 0, "zhang": 0, "yanyan": 0, "lan": 0, "liwei": 0, "wang": 0, "tie": 0, "yan": 0, "liu": 0, "On": 0, "layer": [0, 46], "architectur": 0, "2020": 0, "2002": 0, "04745": 0, "sequenc": [1, 10, 11, 13, 20, 21, 22, 28, 32, 36, 39, 42], "model": [1, 12, 36, 37, 45], "toolkit": 1, "allow": [1, 4, 20, 21], "research": 1, "develop": 1, "train": [1, 10, 11, 12, 13], "custom": 1, "translat": [1, 44], "summar": 1, "languag": [1, 44], "other": [1, 6], "content": [1, 24], "gener": [1, 44], "task": [1, 44], "data": [1, 4, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47], "asset": [1, 14, 15, 16], "bibliographi": 1, "provid": [4, 6, 15], "api": [4, 22], "load": [4, 10, 11, 12, 13, 22], "differ": [4, 20, 44], "us": [4, 12, 13, 18, 19, 20, 21, 22, 24, 28, 44, 47], "from": [4, 6, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 36, 42], "A": [4, 20, 21, 24], "place": 4, "where": [4, 10, 37, 43], "ar": [4, 9, 44], "In": [4, 10, 12], "access": 4, "via": 4, "assetstor": 4, "multipl": [4, 19, 20], "By": 4, "default": [4, 39, 47], "look": [4, 6, 24], "up": [4, 20, 24], "follow": [4, 6, 20, 24, 31], "system": [4, 24], "share": [4, 21], "user": 4, "etc": 4, "thi": [4, 6, 9, 10, 11, 12, 13, 14, 18, 19, 21, 22, 24], "can": [4, 6, 17, 21, 22, 24], "chang": 4, "environ": 4, "variabl": [4, 10, 11, 12, 13], "fairseq2_asset_dir": 4, "onli": [4, 22, 39], "avail": 4, "config": 4, "fairseq2_user_asset_dir": 4, "To": 4, "regist": 4, "new": [4, 22], "implement": [4, 10, 11, 44], "assetmetadataprovid": 4, "add": 4, "them": [4, 6, 9, 22], "asset_stor": 4, "here": 4, "an": [4, 10, 11, 12, 13, 14, 18, 21, 23, 24, 28], "exampl": [4, 6, 20, 21, 22, 39], "directori": [4, 24], "pathlib": 4, "import": 4, "path": [4, 24, 31], "fileassetmetadataprovid": 4, "my_dir": 4, "model_stor": 4, "metadata_provid": 4, "append": 4, "yaml": 4, "file": [4, 6, 17, 24, 31, 33, 34, 39], "contain": [4, 10, 11, 12, 13, 14, 21], "inform": [4, 14, 44, 45], "about": [4, 10, 14], "instruct": 4, "util": [4, 47], "generic_load": 4, "modelload": 4, "how": [4, 19], "memori": [4, 22, 24, 44], "each": [4, 10, 11, 13, 14, 20, 21, 22, 33, 46], "must": 4, "have": [4, 6, 20, 21], "2": [4, 6, 10, 20, 22, 39, 46], "mandatori": 4, "attribut": 4, "name": [4, 11, 14, 15, 16, 21, 24, 35, 39, 46], "checkpoint": 4, "identifi": 4, "uniqu": 4, "_across_": 4, "differen": 4, "llm": 4, "assetcard": [4, 16], "altern": 4, "one": [4, 34, 39], "call": [4, 10, 11, 12, 13, 21, 22, 39, 40, 41], "get_metadata": [4, 15], "str": [4, 6, 14, 15, 16, 18, 19, 21, 22, 25, 27, 30, 36, 37, 39, 42, 43, 44], "get": [4, 24, 37, 43], "meta": 4, "given": [4, 24, 39, 40], "python": [6, 18, 21, 24], "build": 6, "c": 6, "datapipelin": [6, 22], "The": [6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 28, 31, 32, 36, 37, 39, 42, 43, 44, 47], "dataload": [6, 21, 39], "abl": 6, "leverag": 6, "sever": [6, 21, 22, 24], "thread": 6, "work": [6, 9], "around": [6, 21], "global": 6, "interpret": 6, "lock": 6, "limit": 6, "also": [6, 10, 21, 24], "better": 6, "perform": 6, "than": [6, 22], "pure": 6, "like": 6, "read_text": [6, 39], "tsv": [6, 39], "map": [6, 21, 22, 24, 39], "lambda": [6, 22, 39], "x": [6, 22, 39], "split": [6, 18, 39], "t": [6, 10, 11, 12, 13, 17, 39], "1": [6, 10, 11, 12, 13, 19, 20, 22, 35, 37, 39, 46], "lower": 6, "filter": [6, 22], "len": 6, "function": [6, 22, 39, 40, 41], "item": [6, 14], "go": [6, 39], "through": 6, "pipelin": [6, 21, 22, 23, 34], "don": 6, "flat": 6, "tensor": [6, 9, 20, 36, 37, 41, 42, 43, 44, 47], "tupl": [6, 20], "dictionari": [6, 20, 21, 39], "oper": [6, 9, 21], "specifi": [6, 14, 15, 16, 19, 22, 24, 46], "specif": [6, 14, 20, 44], "input": [6, 9, 20, 22, 39], "notabl": 6, "datapipelinebuild": [6, 21, 31, 32, 33, 34], "ha": [6, 10, 22], "selector": [6, 19, 22], "argument": [6, 44], "choos": 6, "appli": [6, 19, 22, 46], "If": [6, 14, 20, 21, 22, 31, 44, 47], "3": [6, 12, 20, 22], "select": [6, 22], "third": 6, "foo": 6, "valu": [6, 10, 14, 20, 35, 46], "correspond": [6, 11, 12, 13, 39], "kei": [6, 14, 20, 24], "nest": 6, "separ": [6, 22], "For": [6, 20, 24], "y": 6, "4": [6, 20], "z": 6, "5": [6, 12, 20, 22], "bar": 6, "6": 6, "refer": [6, 10, 12, 44], "accept": 6, "comma": 6, "list": [6, 18, 20, 22, 31, 37, 39, 43], "multipli": 6, "leav": 6, "unmodifi": 6, "helper": 6, "method": 6, "tool": 6, "token": [6, 28, 36, 37, 42, 43, 44], "convert": [6, 39, 47], "byte": [6, 24], "class": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 28, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46], "fairseq2": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], "rank": 9, "size": [9, 22, 28, 41], "devic": [9, 37, 44], "sourc": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], "base": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 28, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46], "abc": [9, 15, 16, 42, 43, 44], "repres": [9, 10, 11, 12, 13, 16, 18, 28, 44], "set": 9, "process": [9, 22], "collect": 9, "paramet": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 31, 32, 36, 37, 39, 42, 43, 44, 47], "int": [9, 10, 11, 12, 13, 20, 22, 24, 28, 39, 40], "number": [9, 10, 11, 12, 13, 22, 37, 43], "part": [9, 22], "associ": [9, 10, 11, 12, 13, 44], "abstract": [9, 15, 16, 42, 43, 44], "all_gath": 9, "output_tensor": 9, "input_tensor": 9, "gather": 9, "put": 9, "singl": [9, 20, 22], "output": 9, "accomod": 9, "all_reduc": 9, "op": 9, "reduc": 9, "across": 9, "reduceoper": 9, "element": [9, 28, 32], "wise": 9, "as_process_group": 9, "return": [9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47], "group": [9, 10, 11, 12, 13], "type": [9, 10, 14, 15, 16, 18, 20, 21, 22, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47], "processgroup": 9, "barrier": 9, "synchron": 9, "close": 9, "destroi": 9, "final": [10, 11, 12, 13, 36, 37, 38], "optim": [10, 11, 12, 13], "lr_schedul": [10, 11, 12, 13], "cycle_len": 10, "num_warmup_step": [10, 11, 12, 13], "cycle_mul": 10, "0": [10, 11, 13, 20, 22, 37, 39, 46], "lr_mul": 10, "start_lr": [10, 11, 13], "final_lr": [10, 13], "last_epoch": [10, 11, 12, 13], "fairseq2lrschedul": [10, 11, 12, 13], "learn": [10, 11, 12, 13], "rate": [10, 11, 12, 13], "schedul": [10, 11, 12, 13], "describ": [10, 12, 20, 28, 46], "dure": [10, 13], "warmup": [10, 11, 12, 13], "eta_t": [10, 11, 12, 13], "eta_": [10, 11, 12, 13], "frac": [10, 11, 12, 13], "t_": [10, 11, 12, 13], "after": [10, 12, 13, 46], "text": [10, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "co": 10, "pi": 10, "current": [10, 11, 12, 13, 21, 22], "anneal": 10, "cycl": 10, "t_i": 10, "step": [10, 11, 12, 13], "taken": 10, "sinc": 10, "last": [10, 11, 12, 13, 20, 22, 24], "total": [10, 13], "within": 10, "th": 10, "e": 10, "length": [10, 20], "cosin": 10, "effect": 10, "start": [10, 35, 46], "larg": [10, 22], "rel": [10, 24], "rapidli": 10, "decreas": [10, 11, 12, 13], "minimum": 10, "befor": 10, "being": [10, 22], "increas": [10, 11, 12, 13, 22], "again": 10, "pleas": 10, "paper": [10, 12], "more": [10, 22, 44], "detail": [10, 19, 22], "addit": 10, "origin": [10, 11, 20], "support": [10, 18], "phase": 10, "linearli": [10, 11, 12, 13], "first": [10, 11, 12, 13, 21, 39], "chainabl": [10, 11, 12, 13], "float": [10, 11, 13, 21, 47], "factor": 10, "grow": 10, "scale": [10, 11], "end": [10, 18, 21, 28], "initi": [10, 11, 13], "respect": [10, 11, 13], "index": [10, 11, 12, 13, 22, 28], "epoch": [10, 11, 12, 13], "get_last_lr": [10, 11, 12, 13], "comput": [10, 11, 12, 13], "load_state_dict": [10, 11, 12, 13, 21], "state_dict": [10, 11, 12, 13, 21, 22], "state": [10, 11, 12, 13, 21, 22], "arg": [10, 11, 12, 13], "dict": [10, 11, 12, 13, 15, 20, 21, 24, 39], "should": [10, 11, 12, 13, 14, 19], "object": [10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 24, 28, 38, 39, 40, 41], "print_lr": [10, 11, 12, 13], "is_verbos": [10, 11, 12, 13], "lr": [10, 11, 12, 13], "none": [10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 24, 28, 31, 34, 35, 37, 38, 39, 41, 43, 44, 46, 47], "displai": [10, 11, 12, 13], "It": [10, 11, 12, 13, 21], "entri": [10, 11, 12, 13, 39], "everi": [10, 11, 12, 13, 22, 32], "self": [10, 11, 12, 13, 22, 39, 40, 41], "__dict__": [10, 11, 12, 13], "which": [10, 11, 12, 13, 44], "version": [11, 22], "noamlr": 11, "preserv": [11, 20], "min": [11, 12], "sqrt": [11, 12], "essenti": 11, "squar": [11, 12], "root": [11, 12, 24], "wa": [11, 20], "propos": 11, "fairseq": 11, "under": [11, 31], "inversesquarerootlr": 11, "thereaft": [11, 12, 13], "proportion": [11, 12], "invers": [11, 12], "section": 12, "et": [12, 46], "al": [12, 46], "author": 12, "dimension": 12, "commonli": 12, "second": [12, 39], "num_step": 13, "power": 13, "polynomi": 13, "decai": 13, "p": 13, "degre": 13, "includ": 13, "over": [13, 21], "expon": 13, "metadata": [14, 15], "hold": 14, "mutablemap": 14, "ani": [14, 15, 20, 21, 22, 24, 29, 32, 47], "held": 14, "card": [14, 16], "piec": 14, "deriv": 14, "field": 14, "doe": 14, "its": [14, 21], "check": 14, "recurs": [14, 31], "assetcardfield": 14, "clear_cach": 15, "clear": 15, "cach": [15, 24], "store": 16, "retrieve_card": 16, "retriev": 16, "except": [17, 23, 26], "rais": [17, 21, 23, 26], "when": [17, 20, 21, 23, 26], "dataset": [17, 26], "read": [17, 21, 22, 23, 24, 26, 32, 33, 34, 39], "": [18, 21, 22, 30, 37, 39, 40, 41, 43, 46], "immut": 18, "utf": 18, "8": [18, 22], "string": [18, 39], "zero": 18, "copi": 18, "marshal": 18, "between": [18, 44], "nativ": [18, 21], "code": 18, "lstrip": 18, "whitespac": 18, "begin": [18, 28, 46], "rstrip": 18, "sep": [18, 39], "word": 18, "delimit": 18, "strip": 18, "pad_valu": [19, 20, 22], "pad_to_multipl": [19, 20, 22], "overrid": [19, 20, 22], "collat": [19, 22], "creat": [19, 20, 21, 22, 39, 44], "batch": [19, 20, 22], "particular": 19, "column": [19, 20, 22, 39], "same": [19, 20, 21, 22, 24], "pad": [19, 20, 28], "idx": 19, "see": [19, 22], "syntax": [19, 22, 31], "concaten": [20, 21, 22], "dimens": 20, "otherwis": 20, "requir": 20, "made": 20, "long": 20, "enough": 20, "fit": 20, "longest": 20, "round": [20, 21], "is_rag": 20, "true": [20, 21, 22, 30, 44], "fals": [20, 21, 22, 34, 36, 37, 39, 44], "seq": [20, 32], "seq_len": 20, "shape": [20, 22, 37, 43, 47], "option": [20, 24, 31], "shortest": 20, "alwai": 20, "collateoptionsoverrid": 20, "__call__": [20, 24, 36, 37, 39, 40, 41, 42, 43], "persist": 21, "disk": 21, "resum": 21, "later": 21, "iter": 21, "twice": 21, "two": 21, "so": [21, 24], "behav": 21, "inconcist": 21, "__iter__": [21, 35, 46], "modifi": 21, "intern": 21, "safe": 21, "static": 21, "concat": 21, "restor": [21, 22], "previous": 21, "reset": 21, "move": 21, "back": 21, "round_robin": 21, "stop_at_shortest": 21, "extract": 21, "robin": 21, "bool": [21, 22, 44], "stop": 21, "reach": 21, "circl": 21, "finish": 21, "until": 21, "sampl": [21, 22], "weight": 21, "data_pipelin": 21, "desir": 21, "distribut": 21, "uniform": 21, "posit": 21, "pass": 21, "zip": [21, 33], "zip_to_shortest": 21, "flatten": 21, "disable_parallel": 21, "togeth": 21, "assign": 21, "sequenti": 21, "properti": [21, 37, 43], "is_broken": 21, "broken": 21, "futur": 21, "datapipelineerror": 21, "and_return": [22, 39], "max_num_warn": 22, "instanc": 22, "bucket": 22, "bucket_s": 22, "drop_remaind": 22, "combin": 22, "consecut": 22, "drop": 22, "case": 22, "fewer": 22, "bucket_by_length": 22, "skip_long_exampl": 22, "similar": 22, "equival": 22, "predic": 22, "keep": [22, 39], "those": 22, "who": 22, "match": [22, 31], "callabl": 22, "fn": 22, "num_parallel_cal": 22, "usag": [22, 39], "yield": 22, "12": 22, "15": 22, "result": 22, "core": 22, "b": 22, "11": 22, "13": 22, "thei": 22, "automat": 22, "chain": 22, "f1": 22, "f2": 22, "effici": 22, "colum": 22, "parallel": 22, "prefetch": 22, "num_exampl": 22, "background": 22, "while": [22, 23, 26, 44], "shard": 22, "shard_idx": 22, "num_shard": 22, "shuffl": 22, "shuffle_window": 22, "strict": 22, "enabl": [22, 24], "fix": 22, "buffer": 22, "intermedi": 22, "randomli": 22, "replac": 22, "full": 22, "save": 22, "ensur": 22, "preemption": 22, "lost": 22, "significantli": 22, "time": 22, "disabl": 22, "skip": 22, "take": 22, "most": 22, "yield_from": 22, "error": 23, "occur": 23, "root_dir": 24, "cached_fd_count": 24, "slice": 24, "big_fil": 24, "txt": 24, "1024": 24, "48": 24, "offset": 24, "pathlik": [24, 31], "warn": 24, "enforc": 24, "happili": 24, "lru": 24, "especi": 24, "filenam": 24, "pars": [24, 40], "memoryblock": 24, "block": 24, "regular": 24, "filemapperoutput": 24, "alia": [25, 27], "union": [25, 27], "cstring": [25, 27, 30, 36, 37, 39, 42, 43], "o": 25, "corrupt": 26, "record": 26, "encount": 26, "unk_idx": 28, "bos_idx": 28, "eos_idx": 28, "pad_idx": 28, "vocabulari": [28, 44, 45], "symbol": [28, 44], "bo": 28, "eo": 28, "unknown": 28, "unk": 28, "typeguard": 30, "pathnam": [31, 33, 34, 38], "pattern": 31, "travers": 31, "stringlik": 31, "non": 31, "empti": 31, "fnmatch": 31, "archiv": 33, "encod": [34, 37, 43, 44], "line_end": 34, "lineend": 34, "infer": 34, "ltrim": 34, "rtrim": 34, "skip_empti": 34, "memory_map": 34, "block_siz": 34, "open": 34, "line": 34, "modul": [35, 46], "qualnam": [35, 46], "boundari": [35, 46], "enum": [35, 46], "classmethod": [35, 46], "member": [35, 46], "definit": [35, 46], "order": [35, 46], "revers": [36, 37], "texttokendecod": [36, 44], "token_indic": [36, 42], "indic": [36, 37, 39, 42, 43, 44], "decod": [36, 42, 44], "decode_from_token": [36, 42], "prefix_token": 37, "suffix_token": 37, "enable_sampl": 37, "nbest_siz": 37, "alpha": 37, "pin_memori": [37, 44], "texttokenencod": [37, 44], "encode_as_token": [37, 43], "prefix_indic": [37, 43], "prefix": [37, 43], "suffix_indic": [37, 43], "suffix": [37, 43], "control_symbol": 38, "exclud": 39, "charact": 39, "tab": 39, "Will": 39, "per": 39, "va": 39, "cc": 39, "BY": 39, "franc": 39, "tatoeba": 39, "en": [39, 44], "fr": 39, "integ": 40, "dtype": [41, 47], "vocab_info": 44, "vocabularyinfo": [44, 45], "create_decod": 44, "create_encod": 44, "lang": 44, "mode": 44, "valid": 44, "concret": 44, "subclass": 44, "typic": 44, "multi": 44, "job": 44, "distinguish": 44, "transcript": 44, "multilingu": 44, "u": 44, "de": 44, "target": 44, "construct": 44, "pin": 44, "create_raw_encod": 44, "raw": 44, "control": 44, "nn": [46, 47], "post": 46, "residu": 46, "connect": 46, "pre": 46, "pre_with_normform": 46, "mask": 47, "boolean": 47, "point": 47}, "objects": {"fairseq2.assets": [[14, 0, 1, "", "AssetCard"], [15, 0, 1, "", "AssetMetadataProvider"], [16, 0, 1, "", "AssetStore"]], "fairseq2.assets.AssetCard": [[14, 1, 1, "", "field"]], "fairseq2.assets.AssetMetadataProvider": [[15, 1, 1, "", "clear_cache"], [15, 1, 1, "", "get_metadata"]], "fairseq2.assets.AssetStore": [[16, 1, 1, "", "retrieve_card"]], "fairseq2.data": [[17, 2, 1, "", "ByteStreamError"], [18, 0, 1, "", "CString"], [19, 0, 1, "", "CollateOptionsOverride"], [20, 0, 1, "", "Collater"], [21, 0, 1, "", "DataPipeline"], [22, 0, 1, "", "DataPipelineBuilder"], [23, 2, 1, "", "DataPipelineError"], [24, 0, 1, "", "FileMapper"], [25, 4, 1, "", "PathLike"], [26, 2, 1, "", "RecordError"], [27, 4, 1, "", "StringLike"], [28, 0, 1, "", "VocabularyInfo"], [29, 6, 1, "", "get_last_failed_example"], [30, 6, 1, "", "is_string_like"], [31, 6, 1, "", "list_files"], [32, 6, 1, "", "read_sequence"], [33, 6, 1, "", "read_zipped_records"]], "fairseq2.data.CString": [[18, 1, 1, "", "lstrip"], [18, 1, 1, "", "rstrip"], [18, 1, 1, "", "split"], [18, 1, 1, "", "strip"]], "fairseq2.data.Collater": [[20, 1, 1, "", "__call__"]], "fairseq2.data.DataPipeline": [[21, 1, 1, "", "__iter__"], [21, 1, 1, "", "concat"], [21, 3, 1, "", "is_broken"], [21, 1, 1, "", "load_state_dict"], [21, 1, 1, "", "reset"], [21, 1, 1, "", "round_robin"], [21, 1, 1, "", "sample"], [21, 1, 1, "", "state_dict"], [21, 1, 1, "", "zip"]], "fairseq2.data.DataPipelineBuilder": [[22, 1, 1, "", "and_return"], [22, 1, 1, "", "bucket"], [22, 1, 1, "", "bucket_by_length"], [22, 1, 1, "", "collate"], [22, 1, 1, "", "filter"], [22, 1, 1, "", "map"], [22, 1, 1, "", "prefetch"], [22, 1, 1, "", "shard"], [22, 1, 1, "", "shuffle"], [22, 1, 1, "", "skip"], [22, 1, 1, "", "take"], [22, 1, 1, "", "yield_from"]], "fairseq2.data.FileMapper": [[24, 1, 1, "", "__call__"]], "fairseq2.data.VocabularyInfo": [[28, 5, 1, "", "bos_idx"], [28, 5, 1, "", "eos_idx"], [28, 5, 1, "", "pad_idx"], [28, 5, 1, "", "size"], [28, 5, 1, "", "unk_idx"]], "fairseq2.data.text": [[35, 0, 1, "", "LineEnding"], [36, 0, 1, "", "SentencePieceDecoder"], [37, 0, 1, "", "SentencePieceEncoder"], [38, 0, 1, "", "SentencePieceModel"], [39, 0, 1, "", "StrSplitter"], [40, 0, 1, "", "StrToIntConverter"], [41, 0, 1, "", "StrToTensorConverter"], [42, 0, 1, "", "TextTokenDecoder"], [43, 0, 1, "", "TextTokenEncoder"], [44, 0, 1, "", "TextTokenizer"], [34, 6, 1, "", "read_text"], [45, 6, 1, "", "vocab_info_from_sentencepiece"]], "fairseq2.data.text.LineEnding": [[35, 1, 1, "", "__iter__"]], "fairseq2.data.text.SentencePieceDecoder": [[36, 1, 1, "", "__call__"], [36, 1, 1, "", "decode_from_tokens"]], "fairseq2.data.text.SentencePieceEncoder": [[37, 1, 1, "", "__call__"], [37, 1, 1, "", "encode_as_tokens"], [37, 3, 1, "", "prefix_indices"], [37, 3, 1, "", "suffix_indices"]], "fairseq2.data.text.StrSplitter": [[39, 1, 1, "", "__call__"]], "fairseq2.data.text.StrToIntConverter": [[40, 1, 1, "", "__call__"]], "fairseq2.data.text.StrToTensorConverter": [[41, 1, 1, "", "__call__"]], "fairseq2.data.text.TextTokenDecoder": [[42, 1, 1, "", "__call__"], [42, 1, 1, "", "decode_from_tokens"]], "fairseq2.data.text.TextTokenEncoder": [[43, 1, 1, "", "__call__"], [43, 1, 1, "", "encode_as_tokens"], [43, 3, 1, "", "prefix_indices"], [43, 3, 1, "", "suffix_indices"]], "fairseq2.data.text.TextTokenizer": [[44, 1, 1, "", "create_decoder"], [44, 1, 1, "", "create_encoder"], [44, 1, 1, "", "create_raw_encoder"]], "fairseq2.gang": [[9, 0, 1, "", "Gang"]], "fairseq2.gang.Gang": [[9, 1, 1, "", "all_gather"], [9, 1, 1, "", "all_reduce"], [9, 1, 1, "", "as_process_group"], [9, 1, 1, "", "barrier"], [9, 1, 1, "", "close"]], "fairseq2.nn.transformer": [[46, 0, 1, "", "TransformerNormOrder"]], "fairseq2.nn.transformer.TransformerNormOrder": [[46, 5, 1, "", "POST"], [46, 5, 1, "", "PRE"], [46, 5, 1, "", "PRE_WITH_NORMFORMER"], [46, 1, 1, "", "__iter__"]], "fairseq2.nn.utils.mask": [[47, 6, 1, "", "to_float_mask"]], "fairseq2.optim.lr_scheduler": [[10, 0, 1, "", "CosineAnnealingLR"], [11, 0, 1, "", "MyleLR"], [12, 0, 1, "", "NoamLR"], [13, 0, 1, "", "PolynomialDecayLR"]], "fairseq2.optim.lr_scheduler.CosineAnnealingLR": [[10, 1, 1, "", "get_last_lr"], [10, 1, 1, "", "load_state_dict"], [10, 1, 1, "", "print_lr"], [10, 1, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.MyleLR": [[11, 1, 1, "", "get_last_lr"], [11, 1, 1, "", "load_state_dict"], [11, 1, 1, "", "print_lr"], [11, 1, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.NoamLR": [[12, 1, 1, "", "get_last_lr"], [12, 1, 1, "", "load_state_dict"], [12, 1, 1, "", "print_lr"], [12, 1, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.PolynomialDecayLR": [[13, 1, 1, "", "get_last_lr"], [13, 1, 1, "", "load_state_dict"], [13, 1, 1, "", "print_lr"], [13, 1, 1, "", "state_dict"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:exception", "3": "py:property", "4": "py:data", "5": "py:attribute", "6": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "exception", "Python exception"], "3": ["py", "property", "Python property"], "4": ["py", "data", "Python data"], "5": ["py", "attribute", "Python attribute"], "6": ["py", "function", "Python function"]}, "titleterms": {"bibliographi": 0, "fairseq2": [1, 4, 6, 17, 23, 26], "document": 1, "refer": 1, "misc": 1, "abc": [2, 3], "protocol": [2, 3], "all": 3, "class": [3, 5, 6], "enum": [3, 7], "function": [3, 8], "asset": 4, "model": 4, "store": 4, "card": 4, "data": [6, 17, 23, 26], "column": 6, "syntax": 6, "public": 6, "us": 6, "api": 6, "text": 6, "gang": 9, "cosineannealinglr": 10, "mylelr": 11, "noamlr": 12, "polynomialdecaylr": 13, "assetcard": 14, "assetmetadataprovid": 15, "assetstor": 16, "bytestreamerror": 17, "cstring": 18, "collateoptionsoverrid": 19, "collat": 20, "datapipelin": 21, "datapipelinebuild": 22, "datapipelineerror": 23, "filemapp": 24, "pathlik": 25, "recorderror": 26, "stringlik": 27, "vocabularyinfo": 28, "get_last_failed_exampl": 29, "is_string_lik": 30, "list_fil": 31, "read_sequ": 32, "read_zipped_record": 33, "read_text": 34, "lineend": 35, "sentencepiecedecod": 36, "sentencepieceencod": 37, "sentencepiecemodel": 38, "strsplitter": 39, "strtointconvert": 40, "strtotensorconvert": 41, "texttokendecod": 42, "texttokenencod": 43, "texttoken": 44, "vocab_info_from_sentencepiec": 45, "transformernormord": 46, "to_float_mask": 47}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9, "sphinx": 57}, "alltitles": {"Bibliography": [[0, "bibliography"]], "fairseq2 documentation": [[1, "fairseq2-documentation"]], "fairseq2 Reference": [[1, null]], "Misc": [[1, null]], "ABCs and Protocols": [[2, "abcs-and-protocols"], [3, "abcs-and-protocols"]], "All": [[3, "all"]], "Classes": [[3, "classes"], [5, "classes"]], "Enums": [[3, "enums"], [7, "enums"]], "Functions": [[3, "functions"], [8, "functions"]], "fairseq2.assets": [[4, "fairseq2-assets"]], "Model store": [[4, "model-store"]], "Model card": [[4, "model-card"]], "fairseq2.data": [[6, "fairseq2-data"]], "Column syntax": [[6, "column-syntax"]], "Public classes used in fairseq2 API:": [[6, "public-classes-used-in-fairseq2-api"]], "fairseq2.data.text": [[6, "fairseq2-data-text"]], "Gang": [[9, "gang"]], "CosineAnnealingLR": [[10, "cosineannealinglr"]], "MyleLR": [[11, "mylelr"]], "NoamLR": [[12, "noamlr"]], "PolynomialDecayLR": [[13, "polynomialdecaylr"]], "AssetCard": [[14, "assetcard"]], "AssetMetadataProvider": [[15, "assetmetadataprovider"]], "AssetStore": [[16, "assetstore"]], "fairseq2.data.ByteStreamError": [[17, "fairseq2-data-bytestreamerror"]], "CString": [[18, "cstring"]], "CollateOptionsOverride": [[19, "collateoptionsoverride"]], "Collater": [[20, "collater"]], "DataPipeline": [[21, "datapipeline"]], "DataPipelineBuilder": [[22, "datapipelinebuilder"]], "fairseq2.data.DataPipelineError": [[23, "fairseq2-data-datapipelineerror"]], "FileMapper": [[24, "filemapper"]], "PathLike": [[25, "pathlike"]], "fairseq2.data.RecordError": [[26, "fairseq2-data-recorderror"]], "StringLike": [[27, "stringlike"]], "VocabularyInfo": [[28, "vocabularyinfo"]], "get_last_failed_example": [[29, "get-last-failed-example"]], "is_string_like": [[30, "is-string-like"]], "list_files": [[31, "list-files"]], "read_sequence": [[32, "read-sequence"]], "read_zipped_records": [[33, "read-zipped-records"]], "read_text": [[34, "read-text"]], "LineEnding": [[35, "lineending"]], "SentencePieceDecoder": [[36, "sentencepiecedecoder"]], "SentencePieceEncoder": [[37, "sentencepieceencoder"]], "SentencePieceModel": [[38, "sentencepiecemodel"]], "StrSplitter": [[39, "strsplitter"]], "StrToIntConverter": [[40, "strtointconverter"]], "StrToTensorConverter": [[41, "strtotensorconverter"]], "TextTokenDecoder": [[42, "texttokendecoder"]], "TextTokenEncoder": [[43, "texttokenencoder"]], "TextTokenizer": [[44, "texttokenizer"]], "vocab_info_from_sentencepiece": [[45, "vocab-info-from-sentencepiece"]], "TransformerNormOrder": [[46, "transformernormorder"]], "to_float_mask": [[47, "to-float-mask"]]}, "indexentries": {"gang (class in fairseq2.gang)": [[9, "fairseq2.gang.Gang"]], "all_gather() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.all_gather"]], "all_reduce() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.all_reduce"]], "as_process_group() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.as_process_group"]], "barrier() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.barrier"]], "close() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.close"]], "cosineannealinglr (class in fairseq2.optim.lr_scheduler)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.state_dict"]], "mylelr (class in fairseq2.optim.lr_scheduler)": [[11, "fairseq2.optim.lr_scheduler.MyleLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.state_dict"]], "noamlr (class in fairseq2.optim.lr_scheduler)": [[12, "fairseq2.optim.lr_scheduler.NoamLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.state_dict"]], "polynomialdecaylr (class in fairseq2.optim.lr_scheduler)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.state_dict"]], "assetcard (class in fairseq2.assets)": [[14, "fairseq2.assets.AssetCard"]], "field() (fairseq2.assets.assetcard method)": [[14, "fairseq2.assets.AssetCard.field"]], "assetmetadataprovider (class in fairseq2.assets)": [[15, "fairseq2.assets.AssetMetadataProvider"]], "clear_cache() (fairseq2.assets.assetmetadataprovider method)": [[15, "fairseq2.assets.AssetMetadataProvider.clear_cache"]], "get_metadata() (fairseq2.assets.assetmetadataprovider method)": [[15, "fairseq2.assets.AssetMetadataProvider.get_metadata"]], "assetstore (class in fairseq2.assets)": [[16, "fairseq2.assets.AssetStore"]], "retrieve_card() (fairseq2.assets.assetstore method)": [[16, "fairseq2.assets.AssetStore.retrieve_card"]], "bytestreamerror": [[17, "fairseq2.data.ByteStreamError"]], "cstring (class in fairseq2.data)": [[18, "fairseq2.data.CString"]], "lstrip() (fairseq2.data.cstring method)": [[18, "fairseq2.data.CString.lstrip"]], "rstrip() (fairseq2.data.cstring method)": [[18, "fairseq2.data.CString.rstrip"]], "split() (fairseq2.data.cstring method)": [[18, "fairseq2.data.CString.split"]], "strip() (fairseq2.data.cstring method)": [[18, "fairseq2.data.CString.strip"]], "collateoptionsoverride (class in fairseq2.data)": [[19, "fairseq2.data.CollateOptionsOverride"]], "collater (class in fairseq2.data)": [[20, "fairseq2.data.Collater"]], "__call__() (fairseq2.data.collater method)": [[20, "fairseq2.data.Collater.__call__"]], "datapipeline (class in fairseq2.data)": [[21, "fairseq2.data.DataPipeline"]], "__iter__() (fairseq2.data.datapipeline method)": [[21, "fairseq2.data.DataPipeline.__iter__"]], "concat() (fairseq2.data.datapipeline static method)": [[21, "fairseq2.data.DataPipeline.concat"]], "is_broken (fairseq2.data.datapipeline property)": [[21, "fairseq2.data.DataPipeline.is_broken"]], "load_state_dict() (fairseq2.data.datapipeline method)": [[21, "fairseq2.data.DataPipeline.load_state_dict"]], "reset() (fairseq2.data.datapipeline method)": [[21, "fairseq2.data.DataPipeline.reset"]], "round_robin() (fairseq2.data.datapipeline static method)": [[21, "fairseq2.data.DataPipeline.round_robin"]], "sample() (fairseq2.data.datapipeline static method)": [[21, "fairseq2.data.DataPipeline.sample"]], "state_dict() (fairseq2.data.datapipeline method)": [[21, "fairseq2.data.DataPipeline.state_dict"]], "zip() (fairseq2.data.datapipeline static method)": [[21, "fairseq2.data.DataPipeline.zip"]], "datapipelinebuilder (class in fairseq2.data)": [[22, "fairseq2.data.DataPipelineBuilder"]], "and_return() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.and_return"]], "bucket() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.bucket"]], "bucket_by_length() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.bucket_by_length"]], "collate() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.collate"]], "filter() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.filter"]], "map() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.map"]], "prefetch() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.prefetch"]], "shard() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.shard"]], "shuffle() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.shuffle"]], "skip() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.skip"]], "take() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.take"]], "yield_from() (fairseq2.data.datapipelinebuilder method)": [[22, "fairseq2.data.DataPipelineBuilder.yield_from"]], "datapipelineerror": [[23, "fairseq2.data.DataPipelineError"]], "filemapper (class in fairseq2.data)": [[24, "fairseq2.data.FileMapper"]], "__call__() (fairseq2.data.filemapper method)": [[24, "fairseq2.data.FileMapper.__call__"]], "pathlike (in module fairseq2.data)": [[25, "fairseq2.data.PathLike"]], "recorderror": [[26, "fairseq2.data.RecordError"]], "stringlike (in module fairseq2.data)": [[27, "fairseq2.data.StringLike"]], "vocabularyinfo (class in fairseq2.data)": [[28, "fairseq2.data.VocabularyInfo"]], "bos_idx (fairseq2.data.vocabularyinfo attribute)": [[28, "fairseq2.data.VocabularyInfo.bos_idx"]], "eos_idx (fairseq2.data.vocabularyinfo attribute)": [[28, "fairseq2.data.VocabularyInfo.eos_idx"]], "pad_idx (fairseq2.data.vocabularyinfo attribute)": [[28, "fairseq2.data.VocabularyInfo.pad_idx"]], "size (fairseq2.data.vocabularyinfo attribute)": [[28, "fairseq2.data.VocabularyInfo.size"]], "unk_idx (fairseq2.data.vocabularyinfo attribute)": [[28, "fairseq2.data.VocabularyInfo.unk_idx"]], "get_last_failed_example() (in module fairseq2.data)": [[29, "fairseq2.data.get_last_failed_example"]], "is_string_like() (in module fairseq2.data)": [[30, "fairseq2.data.is_string_like"]], "list_files() (in module fairseq2.data)": [[31, "fairseq2.data.list_files"]], "read_sequence() (in module fairseq2.data)": [[32, "fairseq2.data.read_sequence"]], "read_zipped_records() (in module fairseq2.data)": [[33, "fairseq2.data.read_zipped_records"]], "read_text() (in module fairseq2.data.text)": [[34, "fairseq2.data.text.read_text"]], "lineending (class in fairseq2.data.text)": [[35, "fairseq2.data.text.LineEnding"]], "__iter__() (fairseq2.data.text.lineending class method)": [[35, "fairseq2.data.text.LineEnding.__iter__"]], "sentencepiecedecoder (class in fairseq2.data.text)": [[36, "fairseq2.data.text.SentencePieceDecoder"]], "__call__() (fairseq2.data.text.sentencepiecedecoder method)": [[36, "fairseq2.data.text.SentencePieceDecoder.__call__"]], "decode_from_tokens() (fairseq2.data.text.sentencepiecedecoder method)": [[36, "fairseq2.data.text.SentencePieceDecoder.decode_from_tokens"]], "sentencepieceencoder (class in fairseq2.data.text)": [[37, "fairseq2.data.text.SentencePieceEncoder"]], "__call__() (fairseq2.data.text.sentencepieceencoder method)": [[37, "fairseq2.data.text.SentencePieceEncoder.__call__"]], "encode_as_tokens() (fairseq2.data.text.sentencepieceencoder method)": [[37, "fairseq2.data.text.SentencePieceEncoder.encode_as_tokens"]], "prefix_indices (fairseq2.data.text.sentencepieceencoder property)": [[37, "fairseq2.data.text.SentencePieceEncoder.prefix_indices"]], "suffix_indices (fairseq2.data.text.sentencepieceencoder property)": [[37, "fairseq2.data.text.SentencePieceEncoder.suffix_indices"]], "sentencepiecemodel (class in fairseq2.data.text)": [[38, "fairseq2.data.text.SentencePieceModel"]], "strsplitter (class in fairseq2.data.text)": [[39, "fairseq2.data.text.StrSplitter"]], "__call__() (fairseq2.data.text.strsplitter method)": [[39, "fairseq2.data.text.StrSplitter.__call__"]], "strtointconverter (class in fairseq2.data.text)": [[40, "fairseq2.data.text.StrToIntConverter"]], "__call__() (fairseq2.data.text.strtointconverter method)": [[40, "fairseq2.data.text.StrToIntConverter.__call__"]], "strtotensorconverter (class in fairseq2.data.text)": [[41, "fairseq2.data.text.StrToTensorConverter"]], "__call__() (fairseq2.data.text.strtotensorconverter method)": [[41, "fairseq2.data.text.StrToTensorConverter.__call__"]], "texttokendecoder (class in fairseq2.data.text)": [[42, "fairseq2.data.text.TextTokenDecoder"]], "__call__() (fairseq2.data.text.texttokendecoder method)": [[42, "fairseq2.data.text.TextTokenDecoder.__call__"]], "decode_from_tokens() (fairseq2.data.text.texttokendecoder method)": [[42, "fairseq2.data.text.TextTokenDecoder.decode_from_tokens"]], "texttokenencoder (class in fairseq2.data.text)": [[43, "fairseq2.data.text.TextTokenEncoder"]], "__call__() (fairseq2.data.text.texttokenencoder method)": [[43, "fairseq2.data.text.TextTokenEncoder.__call__"]], "encode_as_tokens() (fairseq2.data.text.texttokenencoder method)": [[43, "fairseq2.data.text.TextTokenEncoder.encode_as_tokens"]], "prefix_indices (fairseq2.data.text.texttokenencoder property)": [[43, "fairseq2.data.text.TextTokenEncoder.prefix_indices"]], "suffix_indices (fairseq2.data.text.texttokenencoder property)": [[43, "fairseq2.data.text.TextTokenEncoder.suffix_indices"]], "texttokenizer (class in fairseq2.data.text)": [[44, "fairseq2.data.text.TextTokenizer"]], "create_decoder() (fairseq2.data.text.texttokenizer method)": [[44, "fairseq2.data.text.TextTokenizer.create_decoder"]], "create_encoder() (fairseq2.data.text.texttokenizer method)": [[44, "fairseq2.data.text.TextTokenizer.create_encoder"]], "create_raw_encoder() (fairseq2.data.text.texttokenizer method)": [[44, "fairseq2.data.text.TextTokenizer.create_raw_encoder"]], "vocab_info_from_sentencepiece() (in module fairseq2.data.text)": [[45, "fairseq2.data.text.vocab_info_from_sentencepiece"]], "post (fairseq2.nn.transformer.transformernormorder attribute)": [[46, "fairseq2.nn.transformer.TransformerNormOrder.POST"]], "pre (fairseq2.nn.transformer.transformernormorder attribute)": [[46, "fairseq2.nn.transformer.TransformerNormOrder.PRE"]], "pre_with_normformer (fairseq2.nn.transformer.transformernormorder attribute)": [[46, "fairseq2.nn.transformer.TransformerNormOrder.PRE_WITH_NORMFORMER"]], "transformernormorder (class in fairseq2.nn.transformer)": [[46, "fairseq2.nn.transformer.TransformerNormOrder"]], "__iter__() (fairseq2.nn.transformer.transformernormorder class method)": [[46, "fairseq2.nn.transformer.TransformerNormOrder.__iter__"]], "to_float_mask() (in module fairseq2.nn.utils.mask)": [[47, "fairseq2.nn.utils.mask.to_float_mask"]]}})